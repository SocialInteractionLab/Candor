cluster_label == "survey" ~ "research",
cluster_label == "technical issue" ~ "research",
cluster_label == "time" ~ "research",
# INTERACTION
cluster_label == "starting the call" ~ "interaction",
cluster_label == "ending the call" ~ "interaction",
cluster_label == "greeting" ~ "interaction",
cluster_label == "goodbye" ~ "interaction",
cluster_label == "introduction" ~ "interaction",
cluster_label == "ending conversation" ~ "interaction",
# PREFERENCES
cluster_label == "pets" ~ "preferences",
cluster_label == "travel" ~ "preferences",
cluster_label == "mood, preferences" ~ "preferences",
cluster_label == "personal experience" ~ "preferences",
cluster_label == "age" ~ "preferences",
# LOCATION
cluster_label == "weather" ~ "location",
cluster_label == "location" ~ "location",
cluster_label == "living situation, home" ~ "location",
cluster_label == "city, state, country" ~ "location",
cluster_label == "holiday" ~ "location",
# NEWS / POLITICS
cluster_label == "crime, protest, government" ~ "news & politics",
cluster_label == "news, social media" ~ "news & politics",
cluster_label == "election, politics" ~ "news & politics",
cluster_label == "natural disasters, climate" ~ "news & politics",
# ENTERTAINMENT
cluster_label == "music, instruments" ~ "entertainment",
cluster_label == "television, movies" ~ "entertainment",
cluster_label == "items, fashion, clothing" ~ "entertainment",
cluster_label == "food, drink" ~ "entertainment",
cluster_label == "hobbies, activites, sports" ~ "entertainment",
))
# get probabilities of transitioning between each theme
theme_matrix <- transcripts_clusters |>
ungroup() |>
group_by(PID) |>
arrange(turn_id, .by_group = TRUE) |>
select(PID, group_theme) |>
distinct() |>
mutate(current_topic_number = 1:n(),
current_topic = group_theme,
prior_topic_number = lag(current_topic_number),
prior_topic = lag(group_theme)) |>
na.omit() |>
ungroup() |>
group_by(prior_topic, current_topic) |>
summarize(transition_count = n()) |>
ungroup() |>
group_by(prior_topic) |>
mutate(prior_sum = sum(transition_count)) |>
mutate(probability = transition_count/prior_sum)
# create themes
# tag 50 clusters with the 10 cluster groups to give better insight into transitions
transcripts_clusters <- transcripts_clusters |>
mutate(group_theme = case_when(
# COVID
cluster_label == "pandemic, quarantine" ~ "COVID-19",
cluster_label == "masks" ~ "COVID-19",
cluster_label == "covid" ~ "COVID-19",
cluster_label == "health, illness" ~ "COVID-19",
cluster_label == "zoom" ~ "COVID-19",
# RELATIONSHIPS
cluster_label == "family" ~ "relationships",
cluster_label == "relationships" ~ "relationships",
cluster_label == "parents" ~ "relationships",
cluster_label == "kids, children" ~ "relationships",
cluster_label == "people, fictional characters" ~ "relationships",
# WORK
cluster_label == "employment, job" ~ "work",
cluster_label == "work" ~ "work",
cluster_label == "career, profession" ~ "work",
cluster_label == "money, economy" ~ "work",
cluster_label == "future plans" ~ "work",
# SCHOOL
cluster_label == "school" ~ "school",
cluster_label == "college" ~ "school",
cluster_label == "classes, teaching" ~ "school",
cluster_label == "question, discussion" ~ "school",
cluster_label == "technology, computer" ~ "school",
# RESEARCH
cluster_label == "research, study" ~ "research",
cluster_label == "prolific" ~ "research",
cluster_label == "survey" ~ "research",
cluster_label == "technical issue" ~ "research",
cluster_label == "time" ~ "research",
# INTERACTION
cluster_label == "starting the call" ~ "interaction",
cluster_label == "ending the call" ~ "interaction",
cluster_label == "greeting" ~ "interaction",
cluster_label == "goodbye" ~ "interaction",
cluster_label == "introduction" ~ "interaction",
cluster_label == "ending conversation" ~ "interaction",
# PREFERENCES
cluster_label == "pets" ~ "preferences",
cluster_label == "travel" ~ "preferences",
cluster_label == "mood, preferences" ~ "preferences",
cluster_label == "personal experience" ~ "preferences",
cluster_label == "age" ~ "preferences",
# LOCATION
cluster_label == "weather" ~ "location",
cluster_label == "location" ~ "location",
cluster_label == "living situation, home" ~ "location",
cluster_label == "city, state, country" ~ "location",
cluster_label == "holiday" ~ "location",
# NEWS / POLITICS
cluster_label == "crime, protest, government" ~ "news & politics",
cluster_label == "news, social media" ~ "news & politics",
cluster_label == "election, politics" ~ "news & politics",
cluster_label == "natural disasters, climate" ~ "news & politics",
# ENTERTAINMENT
cluster_label == "music, instruments" ~ "entertainment",
cluster_label == "television, movies" ~ "entertainment",
cluster_label == "items, fashion, clothing" ~ "entertainment",
cluster_label == "food, drink" ~ "entertainment",
cluster_label == "hobbies, activites, sports" ~ "entertainment",
))
# get probabilities of transitioning between each cluster
transition_matrix <- transcripts_clusters |>
ungroup() |>
group_by(PID) |>
arrange(turn_id, .by_group = TRUE) |>
select(PID, cluster_label) |>
distinct() |>
mutate(current_topic_number = 1:n(),
current_topic = cluster_label,
prior_topic_number = lag(current_topic_number),
prior_topic = lag(cluster_label)) |>
na.omit() |>
ungroup() |>
group_by(prior_topic, current_topic) |>
summarize(transition_count = n()) |>
ungroup() |>
group_by(prior_topic) |>
mutate(prior_sum = sum(transition_count)) |>
mutate(probability = transition_count/prior_sum)
# get probabilities of transitioning between each theme
theme_matrix <- transcripts_clusters |>
ungroup() |>
group_by(PID) |>
arrange(turn_id, .by_group = TRUE) |>
select(PID, group_theme) |>
distinct() |>
mutate(current_topic_number = 1:n(),
current_topic = group_theme,
prior_topic_number = lag(current_topic_number),
prior_topic = lag(group_theme)) |>
na.omit() |>
ungroup() |>
group_by(prior_topic, current_topic) |>
summarize(transition_count = n()) |>
ungroup() |>
group_by(prior_topic) |>
mutate(prior_sum = sum(transition_count)) |>
mutate(probability = transition_count/prior_sum)
View(theme_matrix)
# highlight the highest probability of transitioning to current theme from each prior theme
top_prob_theme <- theme_matrix |>
group_by(prior_topic) |>
mutate(highlight = probability == max(probability)) |>
ungroup()
# plot!
ggplot(theme_matrix, aes(x = prior_topic, y = current_topic,
fill = probability)) +
geom_tile(color = "white") + # gradient fill
geom_tile(data = subset(top_prob, highlight),
aes(x = prior_topic, y = current_topic,
fill = probability),
color = "black", linewidth = 0.5) + # outline highlight
geom_text(data = subset(top_prob, highlight),
aes(x = prior_topic, y = current_topic, label = round(probability, digits = 2))) +
labs(title = "Transition Matrix",
x = "Prior Topic", y = "Current Topic", fill = "Probability") +
theme_cowplot() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
scale_fill_gradientn(colors = c("white", "#e96052"))
# plot!
ggplot(theme_matrix, aes(x = prior_topic, y = current_topic,
fill = probability)) +
geom_tile(color = "white") + # gradient fill
geom_tile(data = subset(top_prob_theme, highlight),
aes(x = prior_topic, y = current_topic,
fill = probability),
color = "black", linewidth = 0.5) + # outline highlight
geom_text(data = subset(top_prob_theme, highlight),
aes(x = prior_topic, y = current_topic, label = round(probability, digits = 2))) +
labs(title = "Transition Matrix",
x = "Prior Topic", y = "Current Topic", fill = "Probability") +
theme_cowplot() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
scale_fill_gradientn(colors = c("white", "#e96052"))
# highlight the highest probability of transitioning to current theme from each prior theme
top_prob_theme <- theme_matrix |>
group_by(prior_topic) |>
mutate(highlight = probability == max(probability)) |>
ungroup()
# plot!
ggplot(theme_matrix, aes(x = prior_topic, y = current_topic,
fill = probability)) +
geom_tile(color = "white") + # gradient fill
geom_tile(data = subset(top_prob_theme, highlight),
aes(x = prior_topic, y = current_topic,
fill = probability),
color = "black", linewidth = 0.5) + # outline highlight
geom_text(data = subset(top_prob_theme, highlight),
aes(x = prior_topic, y = current_topic, label = round(probability, digits = 2))) +
labs(title = "Transition Matrix",
x = "Prior Topic", y = "Current Topic", fill = "Probability") +
theme_cowplot() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(hjust = 0.5)) +
scale_fill_gradientn(colors = c("white", "#e96052"))
# save
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/theme_transition_matrix.pdf",
width = 8,
height = 6,
units = "in")
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/theme_transition_matrix.png",
width = 8,
height = 6,
units = "in")
# now make a version with themes
# make an edges data frame (edge list)
edges <- theme_matrix |>
select(from = prior_topic, to = current_topic, probability) |>
distinct()
# make a graph object form the edge list
graph <- as_tbl_graph(edges, directed = TRUE)
# add topic base rate as node attribute to graph
V(graph)$prior_sum <- theme_matrix |>
select(prior_topic, prior_sum) |>
distinct() |>
pull(prior_sum)
# create scaled version of probability for visualization
E(graph)$weight <- theme_matrix$probability
# create edges_10 tibble
edges <- as_tibble(igraph::as_data_frame(graph, what = "edges"))
# map node names to each edge
edges <- edges |> mutate(edge_color = as.factor(from))
graph <- graph |>
activate(edges) |>
mutate(edge_color = edges$edge_color) |>
filter(weight >= 0.05)
graph <- graph %>%
mutate(edge_group = as.factor(seq_along(E(graph))))
# plot
set.seed(2)
ggraph(graph, layout = "circle") +
geom_edge_arc(aes(width = weight,  color = edge_color, group = edge_group),
check_overlap = TRUE, angle_calc = "along",
start_cap = circle(0.05, "in"),
end_cap = circle(0.05, "in"), curvature = 0.05) +
geom_node_point(aes(size = prior_sum, color = name)) +
geom_node_text(aes(label = name, color = name)) +
scale_edge_width(range = c(0.1, 2)) +
coord_fixed() +
theme_void() +
scale_edge_color_manual(values = met.brewer("Hiroshige", 10)) +
scale_color_manual(values = met.brewer("Hiroshige", 10)) +
theme(legend.position = "none")
View(edges)
# now make a version with themes
# make an edges data frame (edge list)
edges <- theme_matrix |>
select(from = prior_topic, to = current_topic, probability) |>
distinct()
# make a graph object form the edge list
graph <- as_tbl_graph(edges, directed = TRUE)
# add topic base rate as node attribute to graph
V(graph)$prior_sum <- theme_matrix |>
select(prior_topic, prior_sum) |>
distinct() |>
pull(prior_sum)
# create scaled version of probability for visualization
E(graph)$weight <- theme_matrix$probability
# create edges_10 tibble
edges <- as_tibble(igraph::as_data_frame(graph, what = "edges"))
# map node names to each edge
edges <- edges |> mutate(edge_color = as.factor(from))
graph <- graph |>
activate(edges) |>
mutate(edge_color = edges$edge_color) |>
filter(weight >= 0.1)
graph <- graph %>%
mutate(edge_group = as.factor(seq_along(E(graph))))
# plot
set.seed(2)
ggraph(graph, layout = "circle") +
geom_edge_arc(aes(width = weight,  color = edge_color, group = edge_group),
check_overlap = TRUE, angle_calc = "along",
start_cap = circle(0.05, "in"),
end_cap = circle(0.05, "in"), curvature = 0.05) +
geom_node_point(aes(size = prior_sum, color = name)) +
geom_node_text(aes(label = name, color = name)) +
scale_edge_width(range = c(0.1, 2)) +
coord_fixed() +
theme_void() +
scale_edge_color_manual(values = met.brewer("Hiroshige", 10)) +
scale_color_manual(values = met.brewer("Hiroshige", 10)) +
theme(legend.position = "none")
graph <- graph |>
activate(edges) |>
mutate(edge_color = edges$edge_color) |>
filter(weight >= 0.125)
# now make a version with themes
# make an edges data frame (edge list)
edges <- theme_matrix |>
select(from = prior_topic, to = current_topic, probability) |>
distinct()
# make a graph object form the edge list
graph <- as_tbl_graph(edges, directed = TRUE)
# add topic base rate as node attribute to graph
V(graph)$prior_sum <- theme_matrix |>
select(prior_topic, prior_sum) |>
distinct() |>
pull(prior_sum)
# create scaled version of probability for visualization
E(graph)$weight <- theme_matrix$probability
# create edges_10 tibble
edges <- as_tibble(igraph::as_data_frame(graph, what = "edges"))
# map node names to each edge
edges <- edges |> mutate(edge_color = as.factor(from))
graph <- graph |>
activate(edges) |>
mutate(edge_color = edges$edge_color) |>
filter(weight >= 0.125)
graph <- graph %>%
mutate(edge_group = as.factor(seq_along(E(graph))))
# plot
set.seed(2)
ggraph(graph, layout = "circle") +
geom_edge_arc(aes(width = weight,  color = edge_color, group = edge_group),
check_overlap = TRUE, angle_calc = "along",
start_cap = circle(0.05, "in"),
end_cap = circle(0.05, "in"), curvature = 0.05) +
geom_node_point(aes(size = prior_sum, color = name)) +
geom_node_text(aes(label = name, color = name)) +
scale_edge_width(range = c(0.1, 2)) +
coord_fixed() +
theme_void() +
scale_edge_color_manual(values = met.brewer("Hiroshige", 10)) +
scale_color_manual(values = met.brewer("Hiroshige", 10)) +
theme(legend.position = "none")
# plot
set.seed(2)
ggraph(graph, layout = "circle") +
geom_edge_arc(aes(width = weight,  color = edge_color, group = edge_group),
check_overlap = TRUE, angle_calc = "along",
start_cap = circle(0.05, "in"),
end_cap = circle(0.05, "in"), curvature = 0.05) +
geom_node_point(aes(size = prior_sum, color = name)) +
scale_edge_width(range = c(0.1, 2)) +
coord_fixed() +
theme_void() +
scale_edge_color_manual(values = met.brewer("Hiroshige", 10)) +
scale_color_manual(values = met.brewer("Hiroshige", 10)) +
theme(legend.position = "none")
# save
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/DAG_theme.pdf",
width = 6,
height = 6,
units = "in")
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/DAG_theme.png",
width = 6,
height = 6,
units = "in")
# calculate occurrence of each cluster label at each scaled_turn_id across 200 conversations
# prop = occurrence / 200
topic_occ <- transcripts_clusters |>
select(PID, transcript_id, cluster_label, scaled_turn_id, group_theme) |>
distinct() |>
group_by(transcript_id, scaled_turn_id, cluster_label, group_theme) |>
# create binary indicator of whether a transcript contains the cluster label per turn
summarize(label_present = as.integer(any(PID == PID)), .groups = "drop") |>
ungroup() |>
group_by(scaled_turn_id, cluster_label) |>
# count how many unique transcripts have each label per turn
summarize(transcript_count = sum(label_present), .groups = "drop") |>
ungroup() |>
# now calculate proportion of transcript count out of total transcripts (200)
mutate(prop = transcript_count / 200,
scaled_turn_id = scaled_turn_id*100)
View(topic_occ)
# calculate occurrence of each cluster label at each scaled_turn_id across 200 conversations
# prop = occurrence / 200
topic_occ <- transcripts_clusters |>
select(PID, transcript_id, cluster_label, scaled_turn_id, group_theme) |>
distinct() |>
group_by(transcript_id, scaled_turn_id, cluster_label, group_theme) |>
# create binary indicator of whether a transcript contains the cluster label per turn
summarize(label_present = as.integer(any(PID == PID)), .groups = "drop") |>
ungroup() |>
group_by(scaled_turn_id, cluster_label, group_theme) |>
# count how many unique transcripts have each label per turn
summarize(transcript_count = sum(label_present), .groups = "drop") |>
ungroup() |>
# now calculate proportion of transcript count out of total transcripts (200)
mutate(prop = transcript_count / 200,
scaled_turn_id = scaled_turn_id*100)
# plot
ggplot(topic_occ, aes(x = scaled_turn_id,
y = fct_reorder(cluster_label, scaled_turn_id*prop, .fun = sum),
height = prop, fill = group_theme)) +
geom_density_ridges(stat = "identity", scale = 4, rel_min_height = 0.005) +
scale_x_continuous(expand = c(0, 0), limits = c(0,101)) +
labs(y = "Cluster Label", x = "Conversation Completion (%)") +
scale_fill_manual(values = met.brewer("Hiroshige", 50)) +
theme_cowplot() +
theme(legend.position = "none")
# plot
ggplot(topic_occ, aes(x = scaled_turn_id,
y = fct_reorder(cluster_label, scaled_turn_id*prop, .fun = sum),
height = prop, fill = group_theme)) +
geom_density_ridges(stat = "identity", scale = 4, rel_min_height = 0.005) +
scale_x_continuous(expand = c(0, 0), limits = c(0,101)) +
labs(y = "Cluster Label", x = "Conversation Completion (%)") +
scale_fill_manual(values = met.brewer("Hiroshige", 10)) +
theme_cowplot() +
theme(legend.position = "none")
# plot
ggplot(topic_occ, aes(x = scaled_turn_id,
y = fct_reorder(cluster_label, scaled_turn_id*prop, .fun = sum),
height = prop, fill = group_theme)) +
geom_density_ridges(stat = "identity", scale = 4, rel_min_height = 0.005) +
scale_x_continuous(expand = c(0, 0), limits = c(0,101)) +
labs(y = "Cluster Label", x = "Conversation Completion (%)") +
scale_fill_manual(values = met.brewer("Hiroshige", 10)) +
theme_cowplot() +
theme(legend.position = "none")
# save
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/cluster_ridges.pdf",
width = 6,
height = 10,
units = "in")
ggsave("/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/cogsci/figures/cluster_ridges.png",
width = 6,
height = 10,
units = "in")
cluster_freq <- transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(turn_id)) |>
ungroup() |>
mutate(total_count = sum(cluster_count)) |>
mutate(prop = (cluster_count/total_count)*100) |>
select("word" = cluster_label, "freq" = prop)
View(cluster_freq)
cluster_freq <- transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label) |>
summarize(cluster_count = length(turn_id)) |>
ungroup() |>
mutate(total_count = sum(cluster_count)) |>
mutate(prop = (cluster_count/total_count)*100) |>
select("word" = cluster_label, "freq" = prop)
View(cluster_freq)
cluster_freq <- transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label) |>
summarize(cluster_count = length(scaled_turn_id)) |>
ungroup() |>
mutate(total_count = sum(cluster_count)) |>
mutate(prop = (cluster_count/total_count)*100) |>
select("word" = cluster_label, "freq" = prop)
View(cluster_freq)
cluster_freq <- transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
arrange(cluster_count)
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
arrange(desc(cluster_count))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
arrange(desc(cluster_count, group_theme))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
group_by(group_theme) |>
arrange(desc(cluster_count))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
ungroup() |>
group_by(group_theme) |>
arrange(desc(cluster_count))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
ungroup() |>
group_by(group_theme) |>
arrange(desc(group_theme))
transcripts_clusters |>
ungroup() |>
dplyr::group_by(cluster_label, group_theme) |>
summarize(cluster_count = length(scaled_turn_id)) |>
arrange(desc(cluster_count))
