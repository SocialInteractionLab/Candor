{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a22813",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "This script cleans the raw annotated data, counts number of annotators, and outputs processed annotation data to be merged with CANDOR transcripts.\n",
    "\n",
    "**Authors:** Changyi Zhou, Helen Schmidt  \n",
    "**Python version:** 3.9.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb568c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69541d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data input location\n",
    "input_folder = \"/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/data/raw/full-sample\"\n",
    "# define data output location\n",
    "output_folder = \"/Users/helenschmidt/Library/CloudStorage/GoogleDrive-helenschmidt129@gmail.com/My Drive/SANLab/Experiments/Conversation-Structure/data/processed/full-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a19f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_data_pilot_4:18.csv', 'full_data_s2.csv', 'full_data_s2-5.csv', 'full_data_s2-4.csv', 'full_data_s2-3.csv', 'full_data_s2-2.csv', 'lowqual2.csv', 'lowqual3.csv', 'lowqual1.csv', 'full_data_s1-1.csv', 'full_data_s1-2.csv', 'full_data_s1-3.csv']\n"
     ]
    }
   ],
   "source": [
    "# get files in the input folder\n",
    "files = [file for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "# check the raw files look correct\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7c4b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data_pilot_4:18.csv - Total submissions: 144\n",
      "full_data_s2.csv - Total submissions: 285\n",
      "full_data_s2-5.csv - Total submissions: 54\n",
      "full_data_s2-4.csv - Total submissions: 123\n",
      "full_data_s2-3.csv - Total submissions: 122\n",
      "full_data_s2-2.csv - Total submissions: 203\n",
      "lowqual2.csv - Total submissions: 26\n",
      "lowqual3.csv - Total submissions: 21\n",
      "lowqual1.csv - Total submissions: 92\n",
      "full_data_s1-1.csv - Total submissions: 208\n",
      "full_data_s1-2.csv - Total submissions: 259\n",
      "full_data_s1-3.csv - Total submissions: 135\n",
      "Total submissions across all data files: 1672\n"
     ]
    }
   ],
   "source": [
    "# create empty data frame\n",
    "dataframes = []\n",
    "# count the values and occurrences of annotations in each data file\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'messages' in df.columns:\n",
    "        messages_df = df[df['messages'].notna() & (df['messages'].str.strip() != '')]\n",
    "        if 'data' in messages_df.columns:\n",
    "            messages_df = messages_df.drop(columns=['data'])\n",
    "\n",
    "        dataframes.append(messages_df)\n",
    "\n",
    "        if 'count' in messages_df.columns:\n",
    "            count_values = messages_df['count'].value_counts()\n",
    "\n",
    "            count_values_df = pd.DataFrame({\n",
    "                'count_value': count_values.index,\n",
    "                'occurrences': count_values.values\n",
    "            })\n",
    "\n",
    "            print (f'{file} - Total submissions: {count_values_df[\"occurrences\"].sum()}')\n",
    "\n",
    "        else:\n",
    "            print(\"The 'count' column was not found in the messages DataFrame.\")\n",
    "\n",
    "raw_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# print final number\n",
    "print (f'Total submissions across all data files: {len(raw_combined)}')\n",
    "# display(raw_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35b04067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing count values: []\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check that remaining conversations from the CANDOR data set have been annotated by at least one person (N = 1456 unique transcripts; doesn't include dense subset of 200)\n",
    "\n",
    "expected_counts = set(range(1456))  # 0 to 1455 inclusive\n",
    "all_counts = set()\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=['messages', 'count'])  # only load needed columns\n",
    "    except ValueError:\n",
    "        print(f\"File {file} is missing required columns.\")\n",
    "        continue\n",
    "\n",
    "    # Filter rows with valid messages\n",
    "    filtered = df['messages'].fillna('').str.strip() != ''\n",
    "    counts = df.loc[filtered, 'count'].dropna().astype(int).unique()\n",
    "\n",
    "    all_counts.update(counts)\n",
    "\n",
    "missing_counts = expected_counts - all_counts\n",
    "\n",
    "print(f\"Missing count values: {sorted(missing_counts)}\")\n",
    "print(len(missing_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20b36d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid rows processed: 1672\n"
     ]
    }
   ],
   "source": [
    "# save processed data file\n",
    "final_df = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    for idx, msg in df['messages'].items():\n",
    "        if pd.isna(msg):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = json.loads(msg)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Skipping row {idx} due to JSON decoding error.\")\n",
    "            continue\n",
    "        data_df = pd.DataFrame(data)\n",
    "\n",
    "        data_df['transcript_id'] = df.loc[idx, 'conversation_id']\n",
    "\n",
    "        data_df['count'] = df.loc[idx, 'count']\n",
    "\n",
    "        final_df = pd.concat([final_df, data_df], ignore_index=True)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "# fix spelling on participant ID\n",
    "final_df.rename(columns={'participent_id': 'PID'}, inplace=True)\n",
    "\n",
    "# save data file to processed folder\n",
    "save_path = output_folder + \"/\" + \"full_sample_processed.csv\"\n",
    "final_df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Total valid rows processed: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8222d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants with fewer than 6 annotations = 153\n"
     ]
    }
   ],
   "source": [
    "# print average number of annotations per PID\n",
    "#annotations_per_participant.rename(columns={'new_topic': 'annotation_count'}, inplace=True)\n",
    "#print(annotations_per_participant['annotation_count'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4f0ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique annotated transcripts = 1464\n",
      "Mean annotation count per participant = 20.672738312082576\n",
      "Number of participants with fewer than 6 annotations = 153\n"
     ]
    }
   ],
   "source": [
    "# print number of unique transcripts\n",
    "print(f\"Number of unique annotated transcripts = {final_df['transcript_id'].nunique()}\")\n",
    "\n",
    "# make PID a string instead of a list\n",
    "final_df['PID_str'] = final_df['PID'].apply(lambda x: ''.join(map(str, x)))\n",
    "\n",
    "# get count of annotations per PID\n",
    "annotation_count = final_df.groupby('PID_str')['new_topic'].nunique().reset_index()\n",
    "annotation_count.rename(columns = {'new_topic': 'PID_count'}, inplace=True)\n",
    "\n",
    "# print average number of annotations per PID\n",
    "print(f\"Mean annotation count per participant = {annotation_count['PID_count'].mean()}\")\n",
    "\n",
    "# print the number of participants with fewer than 6 annotations\n",
    "print(f\"Number of participants with fewer than 6 annotations = {(annotation_count['PID_count'] < 6).sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-python3-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
